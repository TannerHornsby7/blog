---
permalink: the-gears-of-impact
lw-was-draft-post: "false"
lw-is-af: "true"
lw-is-debate: "false"
lw-page-url: https://www.lesswrong.com/posts/coQCEe962sjbcCqB9/the-gears-of-impact
lw-is-question: "false"
lw-posted-at: 2019-10-07T14:44:51.212Z
lw-last-modification: None
lw-curation-date: None
lw-frontpage-date: 2019-10-07T06:10:45.213Z
lw-was-unlisted: "false"
lw-is-shortform: "false"
lw-num-comments-on-upload: 16
lw-base-score: 54
lw-vote-count: 18
af-base-score: 18
af-num-comments-on-upload: 0
publish: true
title: "The Gears of Impact"
lw-latest-edit: 2024-08-15T22:30:43.246Z
lw-is-linkpost: "false"
tags: 
  - "understanding-the-world"
  - "impact-regularization"
aliases: 
  - "the-gears-of-impact"
lw-sequence-title: "Reframing Impact"
lw-sequence-image-grid: sequencesgrid/izfzehxanx48hvf10lnl
lw-sequence-image-banner: sequences/zpia9omq0zfhpeyshvev
sequence-link: posts#reframing-impact
prev-post-slug: world-state-is-the-wrong-abstraction-for-impact
prev-post-title: "World State is the Wrong Abstraction for Impact"
next-post-slug: seeking-power-is-often-convergently-instrumental-in-mdps
next-post-title: "Seeking Power is Often Convergently Instrumental in MDPs"
lw-reward-post-warning: "false"
use-full-width-images: "false"
date_published: 10/07/2019
original_url: https://www.lesswrong.com/posts/coQCEe962sjbcCqB9/the-gears-of-impact
skip_import: true
---

![](https://i.imgur.com/hKhkvwg.png)

![](https://i.imgur.com/IXogCtA.png)

![](https://i.imgur.com/2r2DVFx.png)

![](https://i.imgur.com/holekcV.png)

![](https://i.imgur.com/SzFSiEc.png)

![](https://i.imgur.com/wCRzqox.png) ![](https://i.imgur.com/BAWF2q1.png)

![](https://i.imgur.com/UCGx4QR.png )

![](https://i.imgur.com/5YOlvLh.png)![](https://i.imgur.com/yA8wkQP.png)![](https://i.imgur.com/QXG2pVK.png)

![](https://i.imgur.com/27F0KkU.png)

![](https://i.imgur.com/B7rMciV.png)

![](https://i.imgur.com/HIfRI7r.png)

![](https://i.imgur.com/ye9suf7.png)

![](https://i.imgur.com/sMgB7yR.png)

![](https://i.imgur.com/lQ1jYfB.png )

![](https://i.imgur.com/b6pDiKi.png)

[​](​![]\(https://i.imgur.com/iRLXEeH.png)![](https://i.imgur.com/iRLXEeH.png)

![](https://i.imgur.com/uRr6YqY.png )

![](https://i.imgur.com/67uR5SE.png)![](https://i.imgur.com/PFqi66W.png)

![](https://i.imgur.com/GBVahyL.png)

![](https://i.imgur.com/SATKmJJ.png)

![](https://i.imgur.com/v338kDc.png)

![](https://i.imgur.com/oqEeta9.png)

![](https://i.imgur.com/epI7152.png)

![](https://i.imgur.com/dvVEmBs.png) [​](​![]\(https://i.imgur.com/HShpS3u.png)![](https://i.imgur.com/HShpS3u.png)

![](https://i.imgur.com/WjTqF2y.png)

![](https://i.imgur.com/dLUrki7.png)

![](https://i.imgur.com/lDbQW2b.jpg )


> [!exercise]
> Why does instrumental convergence happen? Would it be coherent to imagine a reality without it?

#### Notes

- Here, our descriptive theory relies on our ability to have reasonable beliefs about what we'll do, and how things in the world will affect our later decision-making process. No one knows how to formalize that kind of reasoning, so I'm leaving it a black box: we _somehow _have these reasonable beliefs which are _apparently _used to calculate AU.
- In technical terms, AU calculated with the "could" criterion would be closer to an optimal value function, while actual AU seems to be an on-policy prediction, _whatever that means _in the embedded context. Felt impact corresponds to TD error.
- Framed as a kind of EU, we plausibly use AU to make decisions.
- I'm not claiming normatively that "embedded agentic" EU _should_ be AU; I'm simply using "embedded agentic" as an adjective.